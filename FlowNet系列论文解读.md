
FlowNet是第一次提出使用CNN进行光流估计，第一版效果比传统的方法差一些，第二版在某些方面已经略好于传统方法。    

![](https://ws4.sinaimg.cn/large/006tNc79ly1fyx4qnfqmij30it0do41q.jpg)

## FlowNet1中提出了两种可行的网络结构。    
网络整体上为编码模块接解码模块结构，编码模块均为9层卷积加ReLU激活函数层，解码模块均为4层反卷积加ReLU激活函数层，在文中解码模块又被称为细化模块。整个网络结构类似于FCN(全卷机网络)，由卷积和反卷积层构成，没有全连接层，因此理论上对输入图像的大小没有要求。    
**编码模块**    
根据输入方式的不同，FlowNet又分为FlowNetSimple和FlowNetCorr。
![](https://ws2.sinaimg.cn/large/006tNc79ly1fyx4s52i04j30iu0acte2.jpg)    
FlowNetS（FlowNetSimple） 直接将两张图像按通道维重叠后输入。    
第一个模型：FlowNetS     
主要特色：     
输入由原来的一张图片变为了两张，通道数由3变为6     
FlowNetC （FlowNetCorr）为了提升网络的匹配性能，人为模仿标准的匹配过程，设计出“互相关层”，即先提取特征，再计算特征的相关性。    
图片不再直接放到通道，而是先分别通过一个三层网络 然后进入一个名叫 correlation layer的层。相关性的计算实际上可以看做是两张图像的特征在空间维做卷积运算。     
correlation layer    
该层的主要作用是比较来自两张图片的feature map的关系，**文章用了卷积的形式**，
在两个特征图中做乘法patch比较，包含这个层的网络结构在图2（bottom）中。给定两个多通道的特征图f1、f2，w、h和c是他们的宽度、高度和通道数，我们的关联层就是让网络比较f1中的每个patch和f2中的每个patch。现在我们只考虑两个patch的单独比较。第一个图的以x1为中心的patch和第二个图的以x2位中心的patch之间的关联就定义为：还是比较巧妙的，具体方程如下 ：    、
![](https://ws3.sinaimg.cn/large/006tNc79ly1fyx8e6m4egj309d01qmx3.jpg)    
C代表correlation，f1和f2分别代表两个feature map， k代表要比较的区域，x1，x2分别代表两个feature map上的点。      
方形patch的尺寸为K=2k+1。公式1等同于神经网络中的一个卷积，但不是用滤波器卷积数据，而是用数据卷积数据，所以，没有可训练的权重。计算c(x1,x2)涉及到cKK次乘法，比较所有的patch组合涉及到wwhh次计算，所以很难处理前向后向过程。为了计算，我们限制最大位移d用于比较，而且在两个特征图中也引入了步长stride。这样通过限制x2的范围，只在D=2d+1 （d=20）的邻域中计算关联c(x1,x2)。我们用步长s1（1）和s2（2），来全局quantize x1，在以x1为中心的邻域内quantize x2。理论上，关联的结果是4D的：对两个2D位置的每个组合，我们得到一个关联值，即两个分别包含截取patches值的向量的内积。实际上，我们把相对位置用通道表示，这就意味着我们得到了w*h*D*D大小的输出。在反向过程中，我们求关于每个对应底层blob的导数。     
    
**解码模块**    
在解码细化的过程中，对每层的反卷积ReLU层，不仅输入前一层的输出，同时还输入前一层预测的低尺度的光流和对应编码模块中的特征层。这样使得每一层反卷积层在细化时，不仅可以获得深层的抽象信息，同时还可以获得浅层的具象信息，以弥补因特征空间尺度的缩小而损失的信息。    
![](https://ws4.sinaimg.cn/large/006tNc79ly1fyx4wlcxnoj30hq074djc.jpg)    
**数据集合成**
没有足够的数据去训练，所以合成数据集。人为去合成大量的虚拟图像对。
通过将一些3D椅子模型[3]随机的覆盖在一些从Flickr上检索的图片上合成图像，再对椅子和背景分别做随机的仿射变化。图像虽然看上去不是很自然，但是却很容易的获得了约22k带有光流真值的图像对。如图4，其中光流以颜色编码的形式展示，色调代表方向，强度代表大小。    

充足的数据加上设计好的网络结构，剩下就是训练测试了。    
精度方面，FlowNetC结果出现了过拟合，与FlowNetS相比也是难分伯仲，然而在FlowNet2.0中，研究者又更新了结论。速度方面，在NVIDIA GTX Titan上运行时，FlowNetS的运行时间为0.08s，FlowNetC因为加入了互相关层的计算，因此运行时间增加到0.15s。

## **FlowNet2.0：从追赶到持平**
在FlowNet的基础上进行提升，在速度上只付出了很小的代价，使性能大幅度提升，追平了目前领先的传统方法。    
**改进1：增加了训练数据，改进了训练策略**    
额外增加了具有3维运动的数据库FlyingThings3D[4]和更加复杂的训练策略。
相比于FlyingChair中的图像只具有平面变换，FlyingThings3D中的图像具有真实的3D运动和亮度变化，实验表明，先在FlyingChair上按S_long策略，再在FlyingThings3D上按S_fine策略后，所得结果最好。单独在FlyingThing3D上训练的结果反而下降。文中给出了解释是尽管FlyingThings3D比较真实，包含更丰富的运动信息，但是过早的学习复杂的运动信息反而不易收敛到更好的结果，而先从简单的运动信息学起，由易到难反得到了更好的结果。    
同时，结果发现FlowNetC的性能要高于FlowNetS。    
**改进2：利用堆叠的结构对预测结果进行多级提升**    
实验结果证明在FlowNetC的基础上堆叠FlowNetS，当以每个FlowNet为单位逐个进行训练时，得到的结果最优。也就是说在训练当前FlowNet模块时，前面的FlowNet模块参数均为固定状态。此外，发现后续的堆叠FlowNet模块，除了输入I_1、I_2外，再输入前一模块的预测光流W_i，图像I_2经预测W_i的变换图像I_2(w_i)以及误差图像|I_1-I_2(W_i)|后，可以使新堆叠的FlowNet模块专注去学习I_1与I_2(W_i)之间剩下的运动变换，从而有效的防止堆叠后的网络过拟合。    
![](https://ws4.sinaimg.cn/large/006tNc79ly1fyx5dan3afj30jd0aoju8.jpg)  
实验表明，当以FlowNetC为基础网络，额外堆叠两个FlowNetS模块后，所得结果最好，[2]中用FlowNet2-CSS表示。    
**改进3：针对小位移的情况引入特定的子网络进行处理**    
FlowNet在真实图片的小位移情况下，结果往往不够理想。因此[2]中，针对小位移情况改进了FlowNet模块的结构，首先将编码模块部分中大小为7x7和5x5的卷积核均换为多层3x3卷积核以增加对小位移的分辨率。其次，在解码模块的反卷积层之间，均增加一层卷积层以便对小位移输出更加平滑的光流预测。文中将针对小位移改进后的网络结构命名为FlowNet2-SD。    
在训练数据的选择上，针对小位移，又重新合成了以小位移为主的新的数据库ChairsSDHom,并将此前的堆叠网络FlowNet2-CSS在ChairsSDHom和FlyingThings3D的混合数据上继续微调训练，将结果网络表示为FlowNet2-CSS-ft-sd。     
最后，再利用一个新的小网络对FlowNet2-CSS-ft-sd的结果和FlowNet2-SD的结果进行融合，并将整个网络体系命名为FlowNet2。结构如下：    
![](https://ws2.sinaimg.cn/large/006tNc79ly1fyx5ohv5e2j30si0bxjt7.jpg)    
从实验结果来看，FlowNet2在各个公共数据库上，在精度方面已经追平了目前最好的一些传统算法。同时，在速度上依然保持着高效快速的优势。    
小位移情况下，FlowNet2-CSS的光流预测噪声非常大，而FlowNet2-SD的输出非常光滑，最后融合结果充分利用了FlowNet2-SD的结果。    
大位移情况下，FlowNet2-CSS预测出了大部分运动，而FlowNet2-SD则丢失了大部分运动信息，最后融合结果又很好的利用了FlowNet2-CSS的结果。    
综上，FlowNet2-CSS与FlowNet2-SD做到了很好地互补，共同保证了FlowNet2在各种情况下的预测质量。    
文中还通过将FlowNet2的预测结果直接用于运动分割和动作识别的任务中，证明FlowNet2的精度已完全可以和其他传统算法媲美的程度，已达到可以实际应用的阶段。    
相对于传统方法来看，基于CNN的光流算法沿袭了CNN算法的优势，即具有由数据驱动的学习能力，也就是说，它的预测能力是可以随着不断学习而不断提升的。从FlowNet2.0的提升中我们可以看到，改变训练策略和增加数据种类就使结果得到了提升。这也反过来说明了，数据对于深度学习算法的重要性。    
基于CNN算法由于主要需要的是简单的卷积运算，加上GPU的并行加速，往往可以获得很快运行速度，使得实时的光流预测系统成为可能，促进了光流预测系统的广泛应用。    
 
